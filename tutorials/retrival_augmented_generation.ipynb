{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec838ca-2391-4aac-b71a-d6800b4d9b05",
   "metadata": {},
   "source": [
    "# Retrieval augmented generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef2ffcb-6192-48e7-a3d6-21b147bf98f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my_document.pdf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download a file\n",
    "import wget\n",
    "\n",
    "file_path = \"my_document.pdf\"\n",
    "doc_url = \"https://www.legifrance.gouv.fr/download/file/rxcTl0H4YnnzLkMLiP4x15qORfLSKk_h8QsSb2xnJ8Y=/JOE_TEXTE\"\n",
    "\n",
    "wget.download(doc_url, out=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e17262f-ab1a-439e-8342-10334e377d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request configuration\n",
    "import requests\n",
    "\n",
    "base_url = \"http://localhost:8080/v1\"\n",
    "api_key = \"albert\" # enter any value if no api_key is setup in config.ini file\n",
    "\n",
    "session = requests.session()\n",
    "session.headers = {\"Authorization\": f\"Bearer {api_key}\"}  # skip headers if no api_key is setup in config.ini file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6852fc7a-0b09-451b-bbc2-939fa96a4d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'object': 'upload',\n",
       "   'id': 'a7fdd4e0-f9b5-4b2d-9bde-0a42d097e7cf',\n",
       "   'filename': 'my_document.pdf',\n",
       "   'status': 'success'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload a file\n",
    "import os\n",
    "\n",
    "collection = \"leo\"\n",
    "model = \"BAAI/bge-m3\"\n",
    "params = {\"collection\": collection, \"model\": model} \n",
    "\n",
    "files = {'files': (os.path.basename(file_path), open(file_path, 'rb'), \"application/pdf\")}\n",
    "response = session.post(f\"{base_url}/files\", params=params , files=files)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6d6140-5c91-4c3e-9350-b6c8550ab145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'object': 'file',\n",
       "   'id': 'a7fdd4e0-f9b5-4b2d-9bde-0a42d097e7cf',\n",
       "   'bytes': 133606,\n",
       "   'filename': 'my_document.pdf',\n",
       "   'created_at': 1720606506}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the file ID for RAG\n",
    "response = session.get(f\"{base_url}/files/{collection}\")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0957f09-948e-4e42-9c7c-7283d72d4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = response.json()[\"data\"][0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ae61fc-7042-4b80-831e-4d7ee2ee2430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'id': 'BaseRAG',\n",
       "   'description': 'Base RAG, basic retrival augmented generation.\\n\\n    Args:\\n        embeddings_model (str): OpenAI embeddings model\\n        collection (List[Optional[str]]): Collection names. Defaults to \"user\" parameter.\\n        file_ids (Optional[List[str]], optional): List of file ids for user collections (after upload files). Defaults to None.\\n        k (int, optional): Top K per collection (max: 6). Defaults to 4.\\n        prompt_template (Optional[str], optional): Prompt template. Defaults to DEFAULT_PROMPT_TEMPLATE.',\n",
       "   'object': 'tool'},\n",
       "  {'id': 'UseFiles',\n",
       "   'description': 'Fill your prompt with file contents. Your prompt must contain \"{files}\" placeholder.\\n\\n    Args:\\n        file_ids (List[str]): List of file ids.',\n",
       "   'object': 'tool'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tools\n",
    "response = session.get(f\"{base_url}/tools\")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5cd813-5c19-4219-a404-6ed154991dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base RAG, basic retrival augmented generation.\n",
      "\n",
      "    Args:\n",
      "        embeddings_model (str): OpenAI embeddings model\n",
      "        collection (List[Optional[str]]): Collection names. Defaults to \"user\" parameter.\n",
      "        file_ids (Optional[List[str]], optional): List of file ids for user collections (after upload files). Defaults to None.\n",
      "        k (int, optional): Top K per collection (max: 6). Defaults to 4.\n",
      "        prompt_template (Optional[str], optional): Prompt template. Defaults to DEFAULT_PROMPT_TEMPLATE.\n"
     ]
    }
   ],
   "source": [
    "# Display tools parameters\n",
    "print(response.json()[\"data\"][0][\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f7bfe0-161f-442a-ae00-b2e4a64a7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client configuration\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=base_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f374c1ad-b5ec-4870-a11a-953c7d219f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selon les documents, Ulrich Tan est le chef du pôle Datamin du département \"Etalab\".\n"
     ]
    }
   ],
   "source": [
    "# Chat completions\n",
    "user = \"leo\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"AgentPublic/llama3-instruct-8b\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Qui est Ulrich Tan ?\"}],\n",
    "    \"stream\": False,\n",
    "    \"n\": 1,\n",
    "    \"user\": user,\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"function\": {\n",
    "                \"name\": \"BaseRAG\",\n",
    "                \"parameters\": {\n",
    "                    \"embeddings_model\": model, \n",
    "                    \"collections\": [collection],\n",
    "                    \"k\": 2\n",
    "                }\n",
    "            },\n",
    "            \"type\": \"function\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = client.chat.completions.create(**data)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd19051-bb51-4b0c-b300-f86b39f17ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qui est Ulrich Tan ?\n"
     ]
    }
   ],
   "source": [
    "# View chat history\n",
    "chat_id = response.id\n",
    "\n",
    "response = session.get(url=f\"{base_url}/chat/history/{user}/{chat_id}\")\n",
    "print(response.json()[\"messages\"][0][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
