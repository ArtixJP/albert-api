{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d87e1a-014f-43a2-a0a5-703bd158f0f9",
   "metadata": {},
   "source": [
    "# Chat completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a18feb-e58b-4fb3-809e-045a81bec9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"API URL\" # e.g. \"http://localhost:8000/v1/\"\n",
    "api_key = \"YOUR API KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad575a2a-f742-477c-a15f-39857e7d326c",
   "metadata": {},
   "source": [
    "## Without chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638096e3-e884-4590-8e1e-0ae29d46818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client configuration\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=base_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f700cab-e53f-4a4c-8cbc-be9bdf96a7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='cmpl-2fa6f08162cb43b8bd8b38920090a033', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Bonjour ! Je suis Albert, un modèle linguistique d'intelligence artificielle. Je suis ravi de discuter avec toi ! Qu'est-ce que tu veux parler ou demander ?\", role='assistant', function_call=None, tool_calls=[]), stop_reason=128009)], created=1720595202, model='AgentPublic/llama3-instruct-8b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=41, prompt_tokens=14, total_tokens=55))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstreamed chat\n",
    "data = {\n",
    "    \"model\": \"AgentPublic/llama3-instruct-8b\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Salut Albert !\"}],\n",
    "    \"stream\": False,\n",
    "    \"n\": 1,\n",
    "}\n",
    "\n",
    "client.chat.completions.create(**data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbc896-3dd0-45b7-9a07-4dd483dbdd51",
   "metadata": {},
   "source": [
    "## With chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1f0bc-de0e-42d8-8433-8a1b46a7c527",
   "metadata": {},
   "source": [
    "Because chat history need a `id` parameters (for chat ID) and this parameters is not currently supported by official OpenAI Python client, you need to request Albert API by *requests* npackage (native Python). We currently works to deploy a Albert Python client to support this parameters.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ef06d6-1f1a-4003-8b85-8f225bc4c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request configuration\n",
    "import requests\n",
    "\n",
    "session = requests.session()\n",
    "session.headers = {\"Authorization\": f\"Bearer {api_key}\"}  # skip headers if no api_key is setup in config.ini file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eec578-2b62-46a5-a672-2cc3dd6f1992",
   "metadata": {},
   "source": [
    "The chat will keep the history of the conversation as long as the `user` parameter is set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d60dff87-eb79-46d0-8c7d-e54cf33d3181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '91d4ed10-9ba4-409c-8c15-01548f7f8a68',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': \"Salut ! Comment vas-tu aujourd'hui ? Je suis Albert, un modèle de langage artificiel, et je suis là pour discuter avec toi ! Qu'est-ce que tu veux parler de ?\",\n",
       "    'role': 'assistant',\n",
       "    'function_call': None,\n",
       "    'tool_calls': []},\n",
       "   'stop_reason': 128009}],\n",
       " 'created': 1720595309,\n",
       " 'model': 'AgentPublic/llama3-instruct-8b',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 44, 'prompt_tokens': 14, 'total_tokens': 58}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstreamed chat\n",
    "user = \"leo\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"AgentPublic/llama3-instruct-8b\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\":\"Salut Albert !\"}],\n",
    "    \"stream\": False,\n",
    "    \"n\": 1,\n",
    "    \"user\": user, # to start a conversation with chat history, setup a user name\n",
    "}\n",
    "\n",
    "response = session.post(url=f\"{base_url}/chat/completions\", json=data)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfec4f8-3c73-4eb7-a8d1-ad7adfb175f9",
   "metadata": {},
   "source": [
    "Now, to continue the conversation with the current chat history, you need to pass the `id` parameter that was returned in the previous template response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a062fab-d72d-4f82-a69d-1a74ad98a214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd433a128-8b53-42bd-b89f-156c75e102b3',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Votre précédent message est également : \"Salut Albert !\"',\n",
       "    'role': 'assistant',\n",
       "    'function_call': None,\n",
       "    'tool_calls': []},\n",
       "   'stop_reason': 128009}],\n",
       " 'created': 1720595300,\n",
       " 'model': 'AgentPublic/llama3-instruct-8b',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 14, 'prompt_tokens': 162, 'total_tokens': 176}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_id = response.json()[\"id\"]\n",
    "\n",
    "data = {\n",
    "    \"model\": \"AgentPublic/llama3-instruct-8b\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\":\"Quel est mon précédent message ?\"}],\n",
    "    \"stream\": False,\n",
    "    \"n\": 1,\n",
    "    \"user\": user,\n",
    "    \"id\": chat_id # to follow a conversation with chat history, setup the previous chat id\n",
    "}\n",
    "response = session.post(url=f\"{base_url}/chat/completions\", json=data)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac189b1-23e8-4fd8-8e6e-151fe98ec21e",
   "metadata": {},
   "source": [
    "You can resume a past conversation by passing the `id` parameter and the correct chat ID. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
