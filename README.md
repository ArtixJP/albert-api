# Albert API

## FonctionnalitÃ©s

### OpenAI conventions

En ce base sur le [client officiel python d'OpenAI](https://github.com/openai/openai-python/tree/main), Albert API expose des endpoints respectant les conventions dÃ©finies par OpenAI : 

- `/v1/models`
- `/v1/completions`
- `/v1/chat/completions`
- `/v1/embeddings`

Ce formalisme permet d'intÃ©grer facilement l'API Albert avec des librairies tierces comme [Langchain](https://www.langchain.com/) ou [LlamaIndex](https://www.llamaindex.ai/).

### Converser avec un modÃ¨le de langage (chat memory)

Albert API intÃ¨gre nativement la mÃ©morisation des messages pour les conversations sans surcharger d'arguments le endpoint `/v1/chat/completions` par rapport Ã  la documentation d'OpenAI. Cela consiste Ã  envoyer Ã  chaque requÃªte au modÃ¨le l'historique de la conversation pour lui fournir le contexte.

> ğŸ“– [Notebook de dÃ©monstration](./tutorials/chat_completions.ipynb)

### AccÃ©der Ã  plusieurs modÃ¨les de langage (multi models)

GrÃ¢ce Ã  un fichier de configuration (*[config.example.yml](./config.example.yml)*) vous pouvez connecter autant d'API de modÃ¨les que vous le souhaitez. L'API Albert se charge de mutualiser l'accÃ¨s Ã  tous ces modÃ¨les dans une unique API. Vous pouvez constater les diffÃ©rents modÃ¨les accessibles en appelant le endpoint `/v1/models`.

> ğŸ“– [Notebook de dÃ©monstration](./tutorials/models.ipynb)

### FonctionnalitÃ©s avancÃ©es (tools) 

Les tools sont une fonctionnalitÃ© dÃ©finie OpenAI que l'on surcharge dans le cas de l'API Albert pour permettre de configurer des tÃ¢ches spÃ©ficiques comme du RAG ou le rÃ©sumÃ©. Vous pouvez appelez le endpoint `/tools` pour voir la liste des tools disponibles.

![](./docs/assets/chatcompletion.png)

#### Interroger des documents (RAG)

> ğŸ“– [Notebook de dÃ©monstration](./tutorials/retrival_augmented_generation.ipynb)

#### RÃ©sumer un document (summarize)

> ğŸ“– [Notebook de dÃ©monstration](./tutorials/summarize.ipynb)
